{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":46125,"databundleVersionId":4972941,"sourceType":"competition"},{"sourceId":10744281,"sourceType":"datasetVersion","datasetId":6663047}],"dockerImageVersionId":30397,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CLIP With early stopping\n\naccuracy: 0.7321  \nval_accuracy: 0.6949  \nPrecision: 0.4666  \nRecall: 0.4671  \nF1-Score: 0.4604  \nWeighted F1-Score: 0.6787","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Concatenate image and text features\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        combined_features = Concatenate()([image_features, text_features])\n        \n        # Classification head\n        x = Dense(512, activation='relu')(combined_features)\n        x = Dropout(0.3)(x)\n        x = LayerNormalization()(x)\n        x = Dense(256, activation='relu')(x)\n        x = Dropout(0.2)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5)\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, epochs=30):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        callbacks=callbacks\n    )\n    \n    return model, history\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    roc_auc = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr')\n    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T16:48:08.022272Z","iopub.execute_input":"2025-02-15T16:48:08.022609Z","iopub.status.idle":"2025-02-15T17:01:10.281724Z","shell.execute_reply.started":"2025-02-15T16:48:08.022539Z","shell.execute_reply":"2025-02-15T17:01:10.280823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping\n\naccuracy: 0.7624  \nval_accuracy: 0.7177     \nPrecision: 0.6341  \nRecall: 0.4891  \nF1-Score: 0.4912  \nWeighted F1-Score: 0.6910    ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Concatenate image and text features\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        combined_features = Concatenate()([image_features, text_features])\n        \n        # Classification head\n        x = Dense(512, activation='relu')(combined_features)\n        x = Dropout(0.3)(x)\n        x = LayerNormalization()(x)\n        x = Dense(256, activation='relu')(x)\n        x = Dropout(0.2)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5)\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, epochs=20):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:03:53.893384Z","iopub.execute_input":"2025-02-15T17:03:53.893718Z","iopub.status.idle":"2025-02-15T17:19:03.196909Z","shell.execute_reply.started":"2025-02-15T17:03:53.893693Z","shell.execute_reply":"2025-02-15T17:19:03.195916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping  \n## Handle class imbalance + Modify model architecture\n\naccuracy: 0.6405  \nval_accuracy: 0.5863     \nPrecision: 0.5504  \nRecall: 0.6473  \nF1-Score: 0.5263  \nWeighted F1-Score: 0.6227    ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.3)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5)\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=20):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:19:03.199532Z","iopub.execute_input":"2025-02-15T17:19:03.199812Z","iopub.status.idle":"2025-02-15T17:34:13.978315Z","shell.execute_reply.started":"2025-02-15T17:19:03.199786Z","shell.execute_reply":"2025-02-15T17:34:13.977505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping  \n## Handle class imbalance + Modify model architecture \n## Increased Dropout + Increased learning rate to 2e-4 + epoch 50\n\naccuracy: 0.9311   \nval_accuracy: 0.6960         \nPrecision: 0.5589  \nRecall: 0.5826  \nF1-Score: 0.5679  \nWeighted F1-Score: 0.7027     ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.4)(x) # increased dropout\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-4) #increased learning rate\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=50):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:34:13.980635Z","iopub.execute_input":"2025-02-15T17:34:13.980920Z","iopub.status.idle":"2025-02-15T18:03:52.500812Z","shell.execute_reply.started":"2025-02-15T17:34:13.980889Z","shell.execute_reply":"2025-02-15T18:03:52.500031Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping  \n## Handle class imbalance + Modify model architecture \n## Increased Dropout + Decreased learning rate to 2e-5 + epoch 50\n\naccuracy: 0.7218  \nval_accuracy: 0.6400         \nPrecision: 0.5467  \nRecall: 0.6223  \nF1-Score: 0.5521  \nWeighted F1-Score: 0.6651     ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.4)(x) # increased dropout\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5) #increased learning rate\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=50):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T18:04:35.392518Z","iopub.execute_input":"2025-02-15T18:04:35.392825Z","iopub.status.idle":"2025-02-15T18:34:19.241878Z","shell.execute_reply.started":"2025-02-15T18:04:35.392801Z","shell.execute_reply":"2025-02-15T18:34:19.240937Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping  \n## Handle class imbalance + Modify model architecture \n## Unfreeze CLIP layer + epoch 50 (high overfitting)\n\naccuracy: 0.7218  \nval_accuracy: 0.6400         \nPrecision: 0.5467  \nRecall: 0.6223  \nF1-Score: 0.5521  \nWeighted F1-Score: 0.6651     ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Fine-tune the entire CLIP model\n        self.clip.trainable = True\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.3)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5)\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=50):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T18:36:14.934033Z","iopub.execute_input":"2025-02-15T18:36:14.934369Z","iopub.status.idle":"2025-02-15T19:42:59.529071Z","shell.execute_reply.started":"2025-02-15T18:36:14.934342Z","shell.execute_reply":"2025-02-15T19:42:59.528141Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP without early stopping with K-fold Cross validation\n## Handle class imbalance + Modify model architecture \n## Increased Dropout + Decreased learning rate to 2e-5 + epoch 50\n\naccuracy: 0.7218  \nval_accuracy: 0.6400         \nPrecision: 0.5467  \nRecall: 0.6223  \nF1-Score: 0.5521  \nWeighted F1-Score: 0.6651     ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.4)(x) # increased dropout\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5) #increased learning rate\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=20):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\nfrom sklearn.model_selection import StratifiedKFold\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Get image paths and texts\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    image_paths = get_image_paths(memes_folder, combined_df['image_name'].tolist())\n    texts = combined_df['Captions'].tolist()\n    labels = combined_df['Label_Sentiment'].values\n\n    # Initialize k-fold cross-validation\n    k = 4  # Number of folds\n    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n    fold_results = []\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n        print(f\"\\nTraining Fold {fold + 1}/{k}\")\n        \n        # Split data into training and validation sets\n        train_image_paths = [image_paths[i] for i in train_idx]\n        train_texts = [texts[i] for i in train_idx]\n        train_labels = labels[train_idx]\n        \n        val_image_paths = [image_paths[i] for i in val_idx]\n        val_texts = [texts[i] for i in val_idx]\n        val_labels = labels[val_idx]\n\n        # Handle class imbalance\n        class_weights = compute_class_weight(\n            class_weight='balanced',\n            classes=np.unique(train_labels),\n            y=train_labels\n        )\n        class_weights = dict(enumerate(class_weights))\n\n        # Train model\n        model, history = train_model(\n            train_image_paths, train_texts, train_labels,\n            val_image_paths, val_texts, val_labels, class_weights\n        )\n\n        # Evaluate model on the validation set\n        val_inputs = process_data_batch(val_image_paths, val_texts, model_handler=CLIPSentimentModel())\n        evaluate_model(model, val_inputs, val_labels, label_map)\n\n        # Store fold results\n        fold_results.append({\n            'val_accuracy': history.history['val_accuracy'][-1],\n            'val_loss': history.history['val_loss'][-1],\n            'val_f1': f1_score(val_labels, np.argmax(model.predict(val_inputs), axis=1), average='weighted')\n        })\n\n    # Aggregate results across folds\n    avg_val_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n    avg_val_loss = np.mean([result['val_loss'] for result in fold_results])\n    avg_val_f1 = np.mean([result['val_f1'] for result in fold_results])\n    print(f\"\\nAverage Validation Accuracy: {avg_val_accuracy:.4f}\")\n    print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n    print(f\"Average Validation Weighted F1-Score: {avg_val_f1:.4f}\")\n\n    # Train final model on the entire dataset (optional)\n    print(\"\\nTraining final model on the entire dataset...\")\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(labels),\n        y=labels\n    )\n    class_weights = dict(enumerate(class_weights))\n\n    final_model, _ = train_model(\n        image_paths, texts, labels,\n        image_paths, texts, labels, class_weights  # Use the same data for validation (optional)\n    )\n\n    # Save the final model\n    final_model.save('final_model.h5')\n    print(\"Final model saved to final_model.h5\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:20:35.343444Z","iopub.execute_input":"2025-02-14T19:20:35.343783Z","iopub.status.idle":"2025-02-14T20:29:04.129790Z","shell.execute_reply.started":"2025-02-14T19:20:35.343757Z","shell.execute_reply":"2025-02-14T20:29:04.128389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLIP best wf score model (Result very poor)\n\nModified loss function. Added Focal Loss Instead of Cross-Entropy.  \n\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow_addons as tfa\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        x = Dense(768, activation='gelu')(combined_features)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        x = Dense(384, activation='gelu')(x)\n        x = Dropout(0.4)(x) # increased dropout\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-4) #increased learning rate\n\n        # Use focal loss to focus on harder to find examples\n        model.compile(\n            optimizer=Adam(learning_rate=2e-5),\n            loss=tfa.losses.SigmoidFocalCrossEntropy(),\n            metrics=['accuracy']\n        )\n\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=30):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:23:28.040512Z","iopub.execute_input":"2025-02-15T22:23:28.041039Z","iopub.status.idle":"2025-02-15T22:33:19.002901Z","shell.execute_reply.started":"2025-02-15T22:23:28.040964Z","shell.execute_reply":"2025-02-15T22:33:19.001530Z"}},"outputs":[{"name":"stdout","text":"Combined DataFrame Columns: Index(['image_name', 'Captions', 'Label_Sentiment'], dtype='object')\nNumber of missing values in 'Label_Sentiment': 12\nUnique values in 'Label_Sentiment': ['positive' 'negative' 'neutral' nan]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1bb88ee8cd64b78803884ab244c4be9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d919a5e1de24d108f8b13a52acbc632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/842k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e2095ecaf44da3a983ed63a83f2134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/512k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b6c41a021c948bea51bb7ae7cc0821e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00363fef399e459dbc89d3415324ef55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8545f7e1fe94f3c8cc5389cbc19fd1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77291eaeaed34c7383477fcefcddbd22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/577M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f433281d7004e7bb3bc9a0580eceaaf"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFCLIPModel.\n\nAll the layers of TFCLIPModel were initialized from the model checkpoint at openai/clip-vit-base-patch32.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFCLIPModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Processing training data...\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).jpg: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).jpg'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/nurani-memes (149).jpg: image file is truncated (3 bytes not processed)\nProcessing validation data...\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png'\nEpoch 1/30\n110/110 [==============================] - 52s 285ms/step - loss: -0.7205 - accuracy: 0.2373 - val_loss: -0.3356 - val_accuracy: 0.1063\nEpoch 2/30\n110/110 [==============================] - 27s 242ms/step - loss: -1.2575 - accuracy: 0.2079 - val_loss: -0.4072 - val_accuracy: 0.0891\nEpoch 3/30\n110/110 [==============================] - 28s 256ms/step - loss: -3.4007 - accuracy: 0.1436 - val_loss: -1.0697 - val_accuracy: 0.0949\nEpoch 4/30\n110/110 [==============================] - 30s 274ms/step - loss: -6.9405 - accuracy: 0.1370 - val_loss: -3.5030 - val_accuracy: 0.1063\nEpoch 5/30\n110/110 [==============================] - 30s 277ms/step - loss: -10.0705 - accuracy: 0.1350 - val_loss: -7.0837 - val_accuracy: 0.1211\nEpoch 6/30\n110/110 [==============================] - 29s 269ms/step - loss: -11.4451 - accuracy: 0.1375 - val_loss: -9.9230 - val_accuracy: 0.1291\nEpoch 7/30\n110/110 [==============================] - 30s 272ms/step - loss: -11.9966 - accuracy: 0.1418 - val_loss: -10.7619 - val_accuracy: 0.1383\nEpoch 8/30\n110/110 [==============================] - 30s 274ms/step - loss: -12.4070 - accuracy: 0.1496 - val_loss: -11.0762 - val_accuracy: 0.1406\nEpoch 9/30\n110/110 [==============================] - 30s 273ms/step - loss: -12.4460 - accuracy: 0.1450 - val_loss: -11.2199 - val_accuracy: 0.1429\nEpoch 10/30\n 20/110 [====>.........................] - ETA: 19s - loss: -13.0154 - accuracy: 0.1109","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2422739275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/2422739275.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m     model, history = train_model(\n\u001b[1;32m    322\u001b[0m         \u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Captions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mtest_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Captions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2422739275.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_image_paths, train_texts, train_labels, val_image_paths, val_texts, val_labels, class_weights, epochs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# callbacks=callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# CLIP best wf score model\n## Increased LR 2e-4\n\nAdded more hidden layers to capture complex relationships.\n\naccuracy: 0.8676   \nval_accuracy: 0.6000  \nPrecision: 0.5227  \nRecall: 0.5607  \nF1-Score: 0.5027  \nWeighted F1-Score: 0.6371  ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow_addons as tfa\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        # Added more hidden layers. larger layers help capture complex features\n        x = Dense(768, activation='gelu')(combined_features)  # Increased units\n        x = Dropout(0.4)(x)  # Higher dropout to prevent overfitting\n        x = LayerNormalization()(x)\n        x = Dense(512, activation='gelu')(x)\n        x = Dropout(0.3)(x)\n        x = Dense(256, activation='gelu')(x)\n        x = Dropout(0.2)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-4) #increased learning rate\n\n        # Use focal loss to focus on harder to find examples\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=30):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        # callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:38:14.954857Z","iopub.execute_input":"2025-02-15T22:38:14.955171Z","iopub.status.idle":"2025-02-15T22:58:30.308558Z","shell.execute_reply.started":"2025-02-15T22:38:14.955145Z","shell.execute_reply":"2025-02-15T22:58:30.307589Z"}},"outputs":[{"name":"stdout","text":"Combined DataFrame Columns: Index(['image_name', 'Captions', 'Label_Sentiment'], dtype='object')\nNumber of missing values in 'Label_Sentiment': 12\nUnique values in 'Label_Sentiment': ['positive' 'negative' 'neutral' nan]\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFCLIPModel.\n\nAll the layers of TFCLIPModel were initialized from the model checkpoint at openai/clip-vit-base-patch32.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFCLIPModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Processing training data...\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).jpg: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).jpg'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/nurani-memes (149).jpg: image file is truncated (3 bytes not processed)\nProcessing validation data...\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png'\nEpoch 1/30\n110/110 [==============================] - 52s 291ms/step - loss: 1.0946 - accuracy: 0.4450 - val_loss: 1.0172 - val_accuracy: 0.5109\nEpoch 2/30\n110/110 [==============================] - 28s 256ms/step - loss: 0.9531 - accuracy: 0.5562 - val_loss: 1.1812 - val_accuracy: 0.4309\nEpoch 3/30\n110/110 [==============================] - 30s 275ms/step - loss: 0.8959 - accuracy: 0.5831 - val_loss: 1.1768 - val_accuracy: 0.4240\nEpoch 4/30\n110/110 [==============================] - 30s 274ms/step - loss: 0.8173 - accuracy: 0.6128 - val_loss: 0.8859 - val_accuracy: 0.5977\nEpoch 5/30\n110/110 [==============================] - 29s 268ms/step - loss: 0.7813 - accuracy: 0.6274 - val_loss: 0.8043 - val_accuracy: 0.6343\nEpoch 6/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.7529 - accuracy: 0.6351 - val_loss: 0.9140 - val_accuracy: 0.5691\nEpoch 7/30\n110/110 [==============================] - 30s 273ms/step - loss: 0.7029 - accuracy: 0.6548 - val_loss: 0.8015 - val_accuracy: 0.6183\nEpoch 8/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.6522 - accuracy: 0.6806 - val_loss: 0.8751 - val_accuracy: 0.5760\nEpoch 9/30\n110/110 [==============================] - 30s 269ms/step - loss: 0.6176 - accuracy: 0.6920 - val_loss: 0.7397 - val_accuracy: 0.6537\nEpoch 10/30\n110/110 [==============================] - 30s 269ms/step - loss: 0.6173 - accuracy: 0.6852 - val_loss: 0.8778 - val_accuracy: 0.6000\nEpoch 11/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.5936 - accuracy: 0.7046 - val_loss: 0.7884 - val_accuracy: 0.6389\nEpoch 12/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.5399 - accuracy: 0.7326 - val_loss: 0.7675 - val_accuracy: 0.6674\nEpoch 13/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.5417 - accuracy: 0.7315 - val_loss: 0.8185 - val_accuracy: 0.6503\nEpoch 14/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.4992 - accuracy: 0.7449 - val_loss: 0.7717 - val_accuracy: 0.6960\nEpoch 15/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.4878 - accuracy: 0.7552 - val_loss: 0.8527 - val_accuracy: 0.6206\nEpoch 16/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.4376 - accuracy: 0.7887 - val_loss: 1.0698 - val_accuracy: 0.5600\nEpoch 17/30\n110/110 [==============================] - 30s 272ms/step - loss: 0.4449 - accuracy: 0.7638 - val_loss: 0.9060 - val_accuracy: 0.6469\nEpoch 18/30\n110/110 [==============================] - 30s 272ms/step - loss: 0.4160 - accuracy: 0.7749 - val_loss: 0.9748 - val_accuracy: 0.6080\nEpoch 19/30\n110/110 [==============================] - 30s 272ms/step - loss: 0.3950 - accuracy: 0.7950 - val_loss: 0.8750 - val_accuracy: 0.6766\nEpoch 20/30\n110/110 [==============================] - 30s 272ms/step - loss: 0.3955 - accuracy: 0.7872 - val_loss: 1.0761 - val_accuracy: 0.6069\nEpoch 21/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.3701 - accuracy: 0.8113 - val_loss: 0.9759 - val_accuracy: 0.6366\nEpoch 22/30\n110/110 [==============================] - 30s 269ms/step - loss: 0.3520 - accuracy: 0.8130 - val_loss: 1.0489 - val_accuracy: 0.6617\nEpoch 23/30\n110/110 [==============================] - 30s 269ms/step - loss: 0.3497 - accuracy: 0.8173 - val_loss: 0.9782 - val_accuracy: 0.6377\nEpoch 24/30\n110/110 [==============================] - 29s 268ms/step - loss: 0.3574 - accuracy: 0.8241 - val_loss: 1.0171 - val_accuracy: 0.6697\nEpoch 25/30\n110/110 [==============================] - 30s 269ms/step - loss: 0.3156 - accuracy: 0.8256 - val_loss: 1.1470 - val_accuracy: 0.6137\nEpoch 26/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.2937 - accuracy: 0.8464 - val_loss: 1.0439 - val_accuracy: 0.6480\nEpoch 27/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.2853 - accuracy: 0.8493 - val_loss: 1.1857 - val_accuracy: 0.6526\nEpoch 28/30\n110/110 [==============================] - 30s 270ms/step - loss: 0.2761 - accuracy: 0.8522 - val_loss: 1.0554 - val_accuracy: 0.6823\nEpoch 29/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.2452 - accuracy: 0.8670 - val_loss: 1.1898 - val_accuracy: 0.6640\nEpoch 30/30\n110/110 [==============================] - 30s 271ms/step - loss: 0.2589 - accuracy: 0.8676 - val_loss: 1.4405 - val_accuracy: 0.6000\nProcessing test data...\n","output_type":"stream"},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFCLIPModel.\n\nAll the layers of TFCLIPModel were initialized from the model checkpoint at openai/clip-vit-base-patch32.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFCLIPModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Error loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).jpg'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (128) (1).png'\nError loading image /kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png: [Errno 2] No such file or directory: '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes/KAM (103) (1).png'\n28/28 [==============================] - 11s 195ms/step\nPrecision: 0.5227\nRecall: 0.5607\nF1-Score: 0.5027\nWeighted F1-Score: 0.6371\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Macro-average ROC-AUC Score: 0.7547\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"28/28 [==============================] - 6s 199ms/step\nWarning: 'Id' column not found in test_df. A unique identifier has been created.\nPredictions saved to submission.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# CLIP best wf score model\n## Decreased LR 2e-5\n\nAdded more hidden layers to capture complex relationships.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom transformers import CLIPProcessor, TFCLIPModel\nfrom tensorflow.keras.layers import Dense, Input, Dropout, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow_addons as tfa\n\ndef load_data(train_path, test_path):\n    \"\"\"Load training and test data\"\"\"\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    return train_df, test_df\n\ndef get_image_paths(directory, image_names):\n    \"\"\"Get full paths for images\"\"\"\n    image_paths = {img: os.path.join(directory, img) for img in image_names}\n    return [image_paths[img] for img in image_names if img in image_paths]\n\nclass CLIPSentimentModel:\n    def __init__(self, num_classes=3):\n        self.num_classes = num_classes\n        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        self.clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n        \n        # Freeze CLIP layers\n        self.clip.trainable = False\n    \n    def process_batch(self, images, texts):\n        \"\"\"Process a batch of images and texts through CLIP\"\"\"\n        inputs = self.processor(\n            images=images,\n            text=texts,\n            return_tensors=\"tf\",\n            padding='max_length',  # Ensure consistent padding\n            truncation=True,       # Truncate sequences longer than max_length\n            max_length=77          # Default sequence length for CLIP\n        )\n        return inputs\n    \n    def build_model(self):\n        # Define inputs\n        input_ids = Input(shape=(77,), dtype=tf.int32, name='input_ids')\n        attention_mask = Input(shape=(77,), dtype=tf.int32, name='attention_mask')\n        pixel_values = Input(shape=(3, 224, 224), dtype=tf.float32, name='pixel_values')\n        \n        # Get CLIP embeddings\n        clip_outputs = self.clip(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pixel_values=pixel_values\n        )\n        \n        # Improved feature fusion\n        image_features = clip_outputs.image_embeds\n        text_features = clip_outputs.text_embeds\n        \n        # Normalize features\n        image_features = tf.math.l2_normalize(image_features, axis=1)\n        text_features = tf.math.l2_normalize(text_features, axis=1)\n        \n        # Multi-modal interaction\n        combined_features = Concatenate()([\n            image_features, \n            text_features, \n            image_features * text_features  # Cross-modality interaction\n        ])\n        \n        # Enhanced classifier head\n        # Added more hidden layers. larger layers help capture complex features\n        x = Dense(768, activation='gelu')(combined_features)  # Increased units\n        x = Dropout(0.4)(x)  # Higher dropout to prevent overfitting\n        x = LayerNormalization()(x)\n        x = Dense(512, activation='gelu')(x)\n        x = Dropout(0.3)(x)\n        x = Dense(256, activation='gelu')(x)\n        x = Dropout(0.2)(x)\n        outputs = Dense(self.num_classes, activation='softmax')(x)\n\n        \n        # Build and compile model\n        model = Model(\n            inputs=[input_ids, attention_mask, pixel_values],\n            outputs=outputs\n        )\n        \n        optimizer = Adam(learning_rate=2e-5) #increased learning rate\n\n        # Use focal loss to focus on harder to find examples\n        model.compile(\n            optimizer=optimizer,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n\n        \n        return model\n\ndef process_data_batch(image_paths, texts, model_handler, batch_size=32):\n    \"\"\"Process data in batches to avoid memory issues\"\"\"\n    all_inputs = []\n    \n    for i in range(0, len(image_paths), batch_size):\n        batch_images = []\n        batch_texts = texts[i:i + batch_size]\n        \n        # Load images for current batch\n        for path in image_paths[i:i + batch_size]:\n            try:\n                image = Image.open(path).convert('RGB')\n                batch_images.append(image)\n            except Exception as e:\n                print(f\"Error loading image {path}: {str(e)}\")\n                # Create a blank image as fallback\n                batch_images.append(Image.new('RGB', (224, 224), color='black'))\n        \n        # Process batch with consistent padding\n        inputs = model_handler.process_batch(batch_images, batch_texts)\n        \n        # Debug: Print shapes of input_ids and attention_mask\n        # print(f\"Batch {i//batch_size + 1}:\")\n        # print(\"input_ids shape:\", inputs['input_ids'].shape)\n        # print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n        # print(\"pixel_values shape:\", inputs['pixel_values'].shape)\n        \n        all_inputs.append(inputs)\n    \n    # Combine all batches\n    combined_inputs = {\n        'input_ids': tf.concat([x['input_ids'] for x in all_inputs], axis=0),\n        'attention_mask': tf.concat([x['attention_mask'] for x in all_inputs], axis=0),\n        'pixel_values': tf.concat([x['pixel_values'] for x in all_inputs], axis=0)\n    }\n    \n    return combined_inputs\n\ndef train_model(train_image_paths, train_texts, train_labels, \n                val_image_paths, val_texts, val_labels, class_weights, epochs=100):\n    # Create model instance\n    model_handler = CLIPSentimentModel()\n    model = model_handler.build_model()\n    \n    print(\"Processing training data...\")\n    train_inputs = process_data_batch(train_image_paths, train_texts, model_handler)\n    \n    print(\"Processing validation data...\")\n    val_inputs = process_data_batch(val_image_paths, val_texts, model_handler)\n    \n    # Callbacks\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=2,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train model\n    history = model.fit(\n        train_inputs,\n        train_labels,\n        validation_data=(val_inputs, val_labels),\n        epochs=epochs,\n        batch_size=32,\n        class_weight=class_weights\n        callbacks=callbacks\n    )\n    \n    return model, history\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n\ndef evaluate_model(model, test_inputs, test_labels, label_map):\n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Calculate metrics\n    precision = precision_score(test_labels, predicted_labels, average='macro')\n    recall = recall_score(test_labels, predicted_labels, average='macro')\n    f1 = f1_score(test_labels, predicted_labels, average='macro')\n    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n    \n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(test_labels, predicted_labels)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n    \n    # ROC-AUC Curve\n    y_test_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=len(label_map))\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    for i, label in enumerate(label_map.keys()):\n        fpr[label], tpr[label], _ = roc_curve(y_test_one_hot[:, i], predictions[:, i])\n        roc_auc[label] = auc(fpr[label], tpr[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(fpr[label], tpr[label], label=f'{label} (AUC = {roc_auc[label]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC-AUC Curve')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n    # ROC-AUC Score (macro-average)\n    roc_auc_macro = roc_auc_score(y_test_one_hot, predictions, multi_class='ovr', average='macro')\n    print(f\"Macro-average ROC-AUC Score: {roc_auc_macro:.4f}\")\n    \n    # Precision-Recall Curve\n    precision_dict = {}\n    recall_dict = {}\n    average_precision_dict = {}\n    for i, label in enumerate(label_map.keys()):\n        precision_dict[label], recall_dict[label], _ = precision_recall_curve(y_test_one_hot[:, i], predictions[:, i])\n        average_precision_dict[label] = auc(recall_dict[label], precision_dict[label])\n    \n    plt.figure(figsize=(8, 6))\n    for label in label_map.keys():\n        plt.plot(recall_dict[label], precision_dict[label], label=f'{label} (AP = {average_precision_dict[label]:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend()\n    plt.show()\n\ndef main():\n    # Load the combined dataset with the correct encoding\n    try:\n        combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='utf-8')\n    except UnicodeDecodeError:\n        # Try alternative encodings if UTF-8 fails\n        try:\n            combined_df = pd.read_csv('/kaggle/input/memosen-with-label/multi-sent.csv', encoding='latin-1')\n        except Exception as e:\n            print(f\"Failed to read the CSV file: {e}\")\n            return\n    \n    # Debug: Print column names to verify\n    print(\"Combined DataFrame Columns:\", combined_df.columns)\n    \n    # Ensure the label column exists\n    if 'Label_Sentiment' not in combined_df.columns:\n        raise KeyError(\"Column 'Label_Sentiment' not found in the combined dataset. Please check the column names.\")\n    \n    # Check for missing or invalid values in the 'Label_Sentiment' column\n    print(\"Number of missing values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].isna().sum())\n    print(\"Unique values in 'Label_Sentiment':\", combined_df['Label_Sentiment'].unique())\n    \n    # Drop rows with missing or invalid labels\n    valid_labels = ['positive', 'neutral', 'negative']\n    combined_df = combined_df[combined_df['Label_Sentiment'].isin(valid_labels)]\n    \n    # Check if the dataset is empty after cleaning\n    if combined_df.empty:\n        raise ValueError(\"The dataset is empty after removing rows with invalid labels.\")\n    \n    # Convert labels to numerical values\n    label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n    combined_df['Label_Sentiment'] = combined_df['Label_Sentiment'].map(label_map)\n    \n    # Split the data into train and test sets (80-20 ratio)\n    train_df, test_df = train_test_split(\n        combined_df, test_size=0.2, random_state=42, stratify=combined_df['Label_Sentiment']\n    )\n    \n    # Copy the labels of the test set for evaluation\n    test_labels_df = test_df[['Label_Sentiment']].copy()\n    \n    # Drop the labels from the test set to simulate unseen data\n    test_df = test_df.drop(columns=['Label_Sentiment'])\n    \n    # Get image paths\n    memes_folder = '/kaggle/input/multimodal-sentiment-analysis-cuet-nlp/Memes/Memes'\n    train_image_paths = get_image_paths(memes_folder, train_df['image_name'].tolist())\n    test_image_paths = get_image_paths(memes_folder, test_df['image_name'].tolist())\n    \n    # Extract labels\n    train_labels = train_df['Label_Sentiment'].values\n    test_labels = test_labels_df['Label_Sentiment'].values\n\n    # Handle class imbalance\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(class_weights))\n    \n    # Train model\n    model, history = train_model(\n        train_image_paths, train_df['Captions'].tolist(), train_labels,\n        test_image_paths, test_df['Captions'].tolist(), test_labels, class_weights\n    )\n    \n    # Process test data\n    print(\"Processing test data...\")\n    model_handler = CLIPSentimentModel()\n    test_inputs = process_data_batch(test_image_paths, test_df['Captions'].tolist(), model_handler)\n    \n    # Evaluate model on the test set\n    evaluate_model(model, test_inputs, test_labels, label_map)\n    \n    # Make predictions\n    predictions = model.predict(test_inputs)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Convert predictions to original labels\n    reverse_label_map = {v: k for k, v in label_map.items()}\n    test_df['Label'] = [reverse_label_map[label] for label in predicted_labels]\n    \n    # Check if 'Id' column exists in test_df\n    if 'Id' not in test_df.columns:\n        # Create a unique identifier if 'Id' column is missing\n        test_df['Id'] = range(1, len(test_df) + 1)\n        print(\"Warning: 'Id' column not found in test_df. A unique identifier has been created.\")\n    \n    # Save predictions\n    test_df[['Id', 'Label']].to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n    \n    return model, history\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}